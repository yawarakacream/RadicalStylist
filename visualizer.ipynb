{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb19f6cb-f0c2-49f9-a2d6-f2c64a71548f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ef328ec-25dd-43fd-b095-ee0511ba0eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "from collections import namedtuple\n",
    "from dataclasses import dataclass\n",
    "from glob import glob\n",
    "from typing import Optional\n",
    "\n",
    "import IPython\n",
    "\n",
    "from matplotlib import pyplot as plt, patches\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from utility import pathstr, char2code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "802511a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "import IPython\n",
    "import ipywidgets\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import PIL\n",
    "\n",
    "\n",
    "def render_images(images, columns=None, scroll=False):\n",
    "    if not isinstance(images, list):\n",
    "        raise Exception()\n",
    "    \n",
    "    columns = columns or len(images)\n",
    "    \n",
    "    children = []\n",
    "    for image in images:\n",
    "        if isinstance(image, tuple):\n",
    "            image, title = image\n",
    "        else:\n",
    "            title = None\n",
    "        \n",
    "        # path\n",
    "        if isinstance(image, str):\n",
    "            image = IPython.display.Image(image)\n",
    "            if isinstance(image.data, str):\n",
    "                raise Exception(f\"image not found: {image.data}\")\n",
    "            image = ipywidgets.Image(value=image.data, layout=ipywidgets.Layout(margin=\"0\", width=\"100%\", object_fit=\"contain\"))\n",
    "        \n",
    "        # ndarray\n",
    "        elif isinstance(image, np.ndarray):\n",
    "            image = PIL.Image.fromarray(image).convert(\"RGB\")\n",
    "            bytesio = io.BytesIO()\n",
    "            image.save(bytesio, format=\"png\")\n",
    "            image = ipywidgets.Image(value=bytesio.getvalue(), layout=ipywidgets.Layout(margin=\"0\", width=\"100%\", object_fit=\"contain\"))\n",
    "        \n",
    "        # ndarray\n",
    "        elif isinstance(image, PIL.Image.Image):\n",
    "            image = image.convert(\"RGB\")\n",
    "            bytesio = io.BytesIO()\n",
    "            image.save(bytesio, format=\"png\")\n",
    "            image = ipywidgets.Image(value=bytesio.getvalue(), layout=ipywidgets.Layout(margin=\"0\", width=\"100%\", object_fit=\"contain\"))\n",
    "        \n",
    "        else:\n",
    "            raise Exception(f\"unsupported image: {image}\")\n",
    "        \n",
    "        if title is None:\n",
    "            children.append(image)\n",
    "        else:\n",
    "            children.append(ipywidgets.VBox(\n",
    "                [ipywidgets.Label(title), image],\n",
    "                layout=ipywidgets.Layout(align_items=\"center\"),\n",
    "            ))\n",
    "        \n",
    "    grid = ipywidgets.GridBox(\n",
    "        children=children,\n",
    "        layout=ipywidgets.Layout(\n",
    "            width=\"100%\",\n",
    "            height=\"fit-content\",\n",
    "            grid_template_columns=f\"repeat({columns}, 1fr)\",\n",
    "            align_items=\"flex-end\",\n",
    "            grid_gap=\"8px\",\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce8c9ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from PIL import Image as PilImage, ImageDraw as PilImageDraw, ImageFont as PilImageFont\n",
    "\n",
    "from radical import Radical, BoundingBox, ClusteringLabel\n",
    "\n",
    "\n",
    "def plot_forecast(ax, image_size, char, radicals):\n",
    "    root_image = PilImage.new(\"RGB\", (image_size, image_size), color=(255, 255, 255))\n",
    "    root_draw = PilImageDraw.Draw(root_image)\n",
    "    \n",
    "    root_draw.rectangle((0, 0, image_size - 1, image_size - 1), outline=(0, 0, 0), width=1)\n",
    "    \n",
    "    font = PilImageFont.truetype(pathstr(\"~/datadisk/dataset/font/NotoSansJP-Regular.ttf\"), size=image_size // 4, index=0)\n",
    "    \n",
    "    for radical in radicals:\n",
    "        if radical.position is None:\n",
    "            pass\n",
    "        elif isinstance(radical.position, BoundingBox):\n",
    "            center_x = int(radical.position.center_x * image_size)\n",
    "            center_y = int(radical.position.center_y * image_size)\n",
    "            left = int(radical.position.left * image_size)\n",
    "            right = int(radical.position.right * image_size)\n",
    "            top = int(radical.position.top * image_size)\n",
    "            bottom = int(radical.position.bottom * image_size)\n",
    "            width = int(radical.position.width * image_size)\n",
    "            height = int(radical.position.height * image_size)\n",
    "\n",
    "            root_draw.rectangle((left, top, right, bottom), outline=(255, 0, 0))\n",
    "            ax.annotate(radical.name, (left, top), ha=\"left\", va=\"top\", fontsize=16, fontweight=\"bold\", color=\"red\")\n",
    "\n",
    "        elif isinstance(radical.position, ClusteringLabel):\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            raise Exception(f\"unknown position: {position}\")\n",
    "\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(root_image, cmap=\"gray\")\n",
    "\n",
    "\n",
    "# plot_forecast(plt.gca(), 512, \"倹\", [\n",
    "#     Radical(\"亻\", BoundingBox(left=0.078125, right=0.3125, top=0.140625, bottom=0.875)),\n",
    "#     Radical(\"人\", BoundingBox(left=0.296875, right=0.859375, top=0.109375, bottom=0.453125)),\n",
    "#     Radical(\"一\", BoundingBox(left=0.4375, right=0.703125, top=0.34375, bottom=0.390625)),\n",
    "#     Radical(\"口\", BoundingBox(left=0.375, right=0.75, top=0.453125, bottom=0.671875)),\n",
    "#     Radical(\"人\", BoundingBox(left=0.328125, right=0.84375, top=0.390625, bottom=0.890625)),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "937a377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from radical import BoundingBox\n",
    "\n",
    "\n",
    "def parse_radical(dct):\n",
    "    try:\n",
    "        return Radical.from_dict(dct)\n",
    "    except: # legacy\n",
    "        return Radical(\n",
    "            name=dct[\"name\"],\n",
    "            position=BoundingBox(\n",
    "                left=dct[\"left\"],\n",
    "                right=dct[\"right\"],\n",
    "                top=dct[\"top\"],\n",
    "                bottom=dct[\"bottom\"],\n",
    "            ),\n",
    "            idx_=dct[\"idx_\"],\n",
    "        )\n",
    "\n",
    "\n",
    "def render_output_test_images(save_path_and_epoch_list):\n",
    "    with open(pathstr(save_path_and_epoch_list[0][0], \"train_info.json\")) as f:\n",
    "        train_info = json.load(f)\n",
    "        epochs = train_info[\"epochs\"]\n",
    "    \n",
    "    num_epochs_digit = len(str(epochs))\n",
    "\n",
    "    test_radicallists = train_info[\"test\"][\"radicallists\"]\n",
    "    for el in test_radicallists:\n",
    "        el[\"elements\"] = [parse_radical(r) for r in el[\"elements\"]]\n",
    "\n",
    "    test_writers = train_info[\"test\"][\"writers\"]\n",
    "    num_test_writers = test_writers if isinstance(test_writers, int) else len(test_writers)\n",
    "\n",
    "    output = []\n",
    "    for i, el in enumerate(test_radicallists):\n",
    "        radicalname = el[\"name\"]\n",
    "        radicallist = el[\"elements\"]\n",
    "\n",
    "        for j, (save_path, epoch) in enumerate(save_path_and_epoch_list):\n",
    "            if j == 0:\n",
    "                forecast_output = ipywidgets.Output(layout=ipywidgets.Layout(width=\"50%\"))\n",
    "                plot_forecast(plt.gca(), 512, radicalname, radicallist)\n",
    "                plt.tight_layout()\n",
    "                forecast_output.append_display_data(plt.gcf().figure)\n",
    "                plt.close()\n",
    "                label = ipywidgets.Label(f\"{radicalname} = {' + '.join(map(lambda r: r.name, radicallist))}\")\n",
    "                output.append(ipywidgets.VBox([label, forecast_output]))\n",
    "            else:\n",
    "                output.append(ipywidgets.Label())\n",
    "            \n",
    "            image = IPython.display.Image(pathstr(save_path, \"generated\", f\"test_{i:0>2}_{str(epoch).zfill(num_epochs_digit)}.png\"))\n",
    "            if isinstance(image.data, str):\n",
    "                image = IPython.display.Image(pathstr(save_path, \"generated\", f\"test_{i:0>2}_{str(epoch).zfill(num_epochs_digit)}.jpg\"))\n",
    "            if isinstance(image.data, str):\n",
    "                raise Exception(f\"image not found: {image.data[:-4]}.(png|jpg)\")\n",
    "            \n",
    "            output.append(ipywidgets.VBox(\n",
    "                children=[\n",
    "                    ipywidgets.Label(\n",
    "                        f\"{save_path.split('/')[-1]} ({epoch=})\",\n",
    "                        overflow=\"hidden\",\n",
    "                    ),\n",
    "                    ipywidgets.Image(\n",
    "                        value=image.data,\n",
    "                        layout=ipywidgets.Layout(\n",
    "                            margin=\"0\",\n",
    "                            object_fit=\"cover\",\n",
    "                        ),\n",
    "                    ),\n",
    "                ],\n",
    "                layout=ipywidgets.Layout(\n",
    "                    width=\"100%\",\n",
    "                    height=\"100%\",\n",
    "                ),\n",
    "            ))\n",
    "\n",
    "    output = ipywidgets.GridBox(\n",
    "        output,\n",
    "        layout=ipywidgets.Layout(\n",
    "            width=\"min(1024px, 100%)\",\n",
    "            grid_template_columns=\"2fr 8fr\",\n",
    "            grid_gap=\"8px\",\n",
    "        )\n",
    "    )\n",
    "    return output\n",
    "\n",
    "\n",
    "# render_output_test_images([\n",
    "#     (\"output/rs test encode_type=3 depth=binary-random\", 1000),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99bf80c1-00b5-4c44-b7cc-46c333954648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_train_output(save_path: str, test_epochs: list[int]):\n",
    "    with open(pathstr(save_path, \"train_info.json\")) as f:\n",
    "        train_info = json.load(f)\n",
    "    \n",
    "        loss = train_info[\"loss\"]\n",
    "    \n",
    "    title_el = ipywidgets.Label(\n",
    "        save_path,\n",
    "        layout=ipywidgets.Layout(\n",
    "            width=\"calc(100% - 2 * var(--jp-widgets-margin))\",\n",
    "            height=\"fit-content\",\n",
    "            white_space=\"normal\",\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    loss_el = ipywidgets.Output(layout=ipywidgets.Layout(width=\"50%\"))\n",
    "    plt.title(\"loss\")\n",
    "    plt.plot(range(len(loss)), loss)\n",
    "    loss_el.append_display_data(plt.gcf().figure)\n",
    "    plt.close()\n",
    "    \n",
    "    test_images = render_output_test_images([(save_path, e) for e in test_epochs])\n",
    "    \n",
    "    container_el = ipywidgets.VBox(\n",
    "        [title_el, loss_el, test_images],\n",
    "        layout=ipywidgets.Layout(width=\"min(1024px, 100%)\"),\n",
    "    )\n",
    "    \n",
    "    return container_el"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13075c6a-0808-4c6d-9a62-11f68615acf2",
   "metadata": {},
   "source": [
    "## 結果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec3e7b5-78cd-4da8-978d-41124be91a54",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### クラスタリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77c10ac8-f8af-41dc-bb7b-37ebfe1275e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# render_train_output(pathstr(\"./output/test writer_mode=dataset/ETL8G_400+KVG_radical(legacy) (encode_type=3, radical_depth=max)\"), [1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da16818c-7681-4f63-aaa2-8cfa60700302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# render_train_output(pathstr(\"./output/test writer_mode=dataset/ETL8G_400+KVG_radical(pad=4,sw=2) encode_type=bbox\"), [1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a164d72-df8a-43e7-a18d-10bd11cb847a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# render_train_output(pathstr(\"./output/test writer_mode=dataset/ETL8G+KVG_radical(pad=4,sw=2) (encode_type=3, radical_depth=max)\"), [500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79b9989c-4467-4f60-be9f-d32e9fdbfdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 部首埋め込み 768 次元のうち 128 次元をクラスタリングのラベルの学習埋め込みに\n",
    "# render_train_output(pathstr(\"./output/test writer_mode=dataset/ETL8G_400+KVG_radical(pad=4,sw=2) encode_type=cl_0 clustering=256(legacy)\"), [1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b637614-fc82-4381-beee-ba4a415c545c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82ae91e9f834d54826a454d8533887a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='/data/nosaka/project/RadicalStylist/output/test writer_mode=dataset/ETL8G_400+KVG_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# KVG の padding を 4 種にした\n",
    "render_train_output(pathstr(\"./output/test writer_mode=dataset/ETL8G_400+KVG_radical(pad={4,8,12,16},sw=2) encode_type=cl_0 clustering=256(legacy)\"), [1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070b2222-bf9e-4f3f-a29e-4682552a8349",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### SVG 合成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f4106a8-fdad-414a-9791-003cf97678f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd004d3b6de14a3db84a58060dd648e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='/data/nosaka/project/RadicalStylist/output/test writer_mode=dataset/ETL8G+KVG_radi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "ETL8G: 141841 件\n",
    "\n",
    "SVG 正規: 2672 件 * 4\n",
    "ETL8G に含まれる部首しか持たない字のみ (常用漢字の個数に近い)\n",
    "\n",
    "SVG 合成: 139169 件 * 4\n",
    "ピクセルの被りが padding=4px, stroke_width=2px で 1 つも起こらないもののみ\n",
    "\n",
    "SVG の * 4 は 4px, 8px, 12px, 16px の 4 種の余白を持つ画像を用意した分\n",
    "\"\"\"\n",
    "# render_train_output(pathstr(\"./output/test writer_mode=dataset/ETL8G(no_bg)+KVG_radical(pad={4,8,12,16},sw=2)+KVG_C(pad={4,8,12,16},sw=2,n_limit=140000) encode_type=cl_0\"), [100])\n",
    "render_train_output(pathstr(\"./output/test writer_mode=dataset/ETL8G+KVG_radical(pad={4,8,12,16},sw=2)+KVG_C(pad={4,8,12,16},sw=2,n_limit=139169) encode_type=cl_0\"), [120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c222899f-c6fd-4806-b72b-264401c607ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nETL8G を 4 倍\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "ETL8G を 4 倍\n",
    "\"\"\"\n",
    "# render_train_output(pathstr(\"./output/test writer_mode=dataset/ETL8G(no_bg)*4+KVG_radical(pad={4,8,12,16},sw=2)+KVG_C(pad={4,8,12,16},sw=2,n_limit=139169) encode_type=cl_0\"), [50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d520553-9c97-46f2-b946-9bed7a55951e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### MSE だと小さい部首より大きい部首のほうが優先されるかもなので変えてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc82528a-f2ce-4792-9a37-5ba1a176c169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor images, radicallists, writerindices in pbar:\\n    weights = torch.ones_like(images)\\n    weights = self.vae.encode(weights)\\n\\n    # # https://stackoverflow.com/questions/59831211/neighbours-of-a-cell-in-matrix-pytorch\\n    # box = torch.ones((3, 3), dtype=images.dtype, device=images.device, requires_grad=False)  \\n    # box = box / box.sum()\\n    # box = box[None, None, ...].repeat(images.size(1), 1, 1, 1)\\n    # weights = F.conv2d(images + (3 / 255), box, padding=1, groups=images.size(1))\\n    # weights = F.batch_norm(weights, torch.zeros(3), torch.ones(3))\\n    # weights = self.vae.encode(weights)\\n\\n    ...\\n\\n    loss = torch.mean(((noise - predicted_noise) ** 2) * weights)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ピクセル毎に重みをつけて vae に入れてかけあわせてみる\n",
    "\"\"\"\n",
    "for images, radicallists, writerindices in pbar:\n",
    "    weights = torch.ones_like(images)\n",
    "    weights = self.vae.encode(weights)\n",
    "\n",
    "    # # https://stackoverflow.com/questions/59831211/neighbours-of-a-cell-in-matrix-pytorch\n",
    "    # box = torch.ones((3, 3), dtype=images.dtype, device=images.device, requires_grad=False)  \n",
    "    # box = box / box.sum()\n",
    "    # box = box[None, None, ...].repeat(images.size(1), 1, 1, 1)\n",
    "    # weights = F.conv2d(images + (3 / 255), box, padding=1, groups=images.size(1))\n",
    "    # weights = F.batch_norm(weights, torch.zeros(3), torch.ones(3))\n",
    "    # weights = self.vae.encode(weights)\n",
    "\n",
    "    ...\n",
    "\n",
    "    loss = torch.mean(((noise - predicted_noise) ** 2) * weights)\n",
    "\"\"\"\n",
    "\n",
    "# render_train_output(pathstr(\"./output/test writer_mode=dataset/ETL8G_400+KVG_radical(pad={4,8,12,16},sw=2) encode_type=cl_0 loss=w_mse\"), [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efdd516c-c275-4d34-b896-860fa2b638fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor images, radicallists, writerindices in pbar:\\n    weights = sum(images.size()) / images.sum(dim=(1, 2, 3)).to(device=self.device)\\n    \\n    ...\\n\\n    loss = torch.sum(torch.mean(((noise - predicted_noise) ** 2), dim=(1, 2, 3)) * weights) / weights.sum()\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# バッチ毎にピクセルの総和の逆数の重みをつける\n",
    "\"\"\"\n",
    "for images, radicallists, writerindices in pbar:\n",
    "    weights = sum(images.size()) / images.sum(dim=(1, 2, 3)).to(device=self.device)\n",
    "    \n",
    "    ...\n",
    "\n",
    "    loss = torch.sum(torch.mean(((noise - predicted_noise) ** 2), dim=(1, 2, 3)) * weights) / weights.sum()\n",
    "\"\"\"\n",
    "\n",
    "# render_train_output(pathstr(\"./output/test writer_mode=dataset/ETL8G_400+KVG_radical(pad={4,8,12,16},sw=2) encode_type=cl_0 loss=mse_w\"), [1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c957fab-b4e2-4786-94c1-7e67175a364a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad285e2ed0b41cb9091362eaa1b818a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridBox(children=(VBox(children=(Label(value='何 = 亻 + 可'), Output(layout=Layout(width='50%'), outputs=({'outpu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "render_output_test_images((\n",
    "    (pathstr(\"./output/test writer_mode=dataset/ETL8G_400+KVG_radical(pad={4,8,12,16},sw=2) encode_type=cl_0 clustering=256(legacy)\"), 1000),\n",
    "    (pathstr(\"./output/test writer_mode=dataset/ETL8G_400+KVG_radical(pad={4,8,12,16},sw=2) encode_type=cl_0 loss=mse_w\"), 1000),\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddc14dff-f083-4ae7-87c8-9bab1b389914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n埋め込みの次元を増やした\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "埋め込みの次元を増やした\n",
    "\"\"\"\n",
    "# render_train_output(pathstr(\"./output/test writer_mode=dataset/ETL8G_400+KVG_radical(pad={4,8,12,16},sw=2) encode_type=cl_0 dim=1536\"), [200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5fb28c-5a70-4dad-b414-5a24defbc35e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850d25c9-631a-49a3-934d-492e6b54a7f6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### NotoSans, NotoSerif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99317d90-cfc8-4c87-aa02-37943979165e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# render_train_output(pathstr(\"./output/test writer_mode=dataset vae=noto*2(n_random=65536,epoch=1)/ETL8G_400+KVG_radical(pad={4,8,12,16},sw=2) encode_type=cl_0\"), [300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "975006ec-eddc-4863-8abe-e294a6698299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# render_train_output(pathstr(\"./output/test writer_mode=dataset vae=noto*2(n_random=65536,epoch=80)/ETL8G*4+KVG_radical(pad={4,8,12,16},sw=2)+KVG_C(pad={4,8,12,16},sw=2,n_limit=139169) encode_type=cl_0\"), [120])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e457305c-5e48-4c37-af82-24fd518db636",
   "metadata": {},
   "source": [
    "#### さなりフォント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "849f7b9a-1d8a-443d-960a-386e4dcd1271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# render_train_output(pathstr(\"./output/test writer_mode=dataset vae=SanariFont001(n_random=262140,epoch=30)/ETL8G_400+KVG_radical(pad={4,8,12,16},sw=2) encode_type=cl_0\"), [100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "676f3f66-ce1a-477b-bf5c-ecc4fb457781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# render_output_test_images((\n",
    "#     (pathstr(\"./output/test writer_mode=dataset/ETL8G_400+KVG_radical(pad={4,8,12,16},sw=2) encode_type=cl_0 clustering=256(legacy)\"), 1000),\n",
    "#     (pathstr(\"./output/test writer_mode=dataset vae=SanariFont001(n_random=262140,epoch=30)/ETL8G_400+KVG_radical(pad={4,8,12,16},sw=2) encode_type=cl_0\"), 1000),\n",
    "# ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deedae1e-cd01-4a69-9272-7cd8e1e73ca6",
   "metadata": {},
   "source": [
    "### こどもの字を入れる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc2f3c9-b55e-4a7a-8c1c-63e4d5298039",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 試験"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2921618d-f10b-4873-a0c4-95a700319acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nETL8G_onlykanji_train (127657 件)\\nこどもの漢字の 2 値化 (3719 件)\\nKVG (2672 * 4 件)\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "ETL8G_onlykanji_train (127657 件)\n",
    "こどもの漢字の 2 値化 (3719 件)\n",
    "KVG (2672 * 4 件)\n",
    "\"\"\"\n",
    "# render_train_output(pathstr(\"./output/nlp2024/nlp2024+KVG(pad={4,8,12,16},sw=2) radenc=cl_0\"), [400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c32a119-795c-4489-959c-4e122f813917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nETL8G_onlykanji_train (127657 件)\\nこどもの漢字の 2 値化 (3719 件)\\nKVG (2672 * 4 件)\\nKVG 合成 (30000 * 4 件)\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "ETL8G_onlykanji_train (127657 件)\n",
    "こどもの漢字の 2 値化 (3719 件)\n",
    "KVG (2672 * 4 件)\n",
    "KVG 合成 (30000 * 4 件)\n",
    "\"\"\"\n",
    "# render_train_output(pathstr(\"./output/nlp2024/nlp2024+KVG(pad={4,8,12,16},sw=2)+KVG_C(pad={4,8,12,16},sw=2,n_limit=30000) radenc=cl_0\"), [150])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8b9bb0-4848-43ef-8248-7eee68b6ec07",
   "metadata": {},
   "source": [
    "#### 本番"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8dd62ff7-64c2-431f-8fbf-e500125bec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# render_train_output(pathstr(\"./output/nlp2024/character nlp2024(kana,kanji)\"), [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8b3b247-6853-4a31-ac95-9112a996a58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1df549fef4a4c228b2df3c12640e2c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='/data/nosaka/project/RadicalStylist/output/nlp2024/character(d=384)_2 nlp2024(kana…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "render_train_output(pathstr(\"./output/nlp2024/character(d=384)_2 nlp2024(kana,kanji)\"), [1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "852ae9af-41dd-4110-9169-f36d0fb9b76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nETL9G_onlykanji_train(sheet=1-1000): 133281 件\\nこどもの漢字: 3719 件\\nKVG: 9964 * 4 件\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "ETL9G_onlykanji_train(sheet=1-1000): 133281 件\n",
    "こどもの漢字: 3719 件\n",
    "KVG: 9964 * 4 件\n",
    "\"\"\"\n",
    "# render_train_output(pathstr(\"./output/nlp2024/radical nlp2024(kana,kanji)+KVG(pad={4,8,12,16},sw=2)\"), [750])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14042dd2-78b1-45f0-a24c-c7236339cd92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2ce1992383b4b599d8c65b6e25b82cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='/data/nosaka/project/RadicalStylist/output/nlp2024/radical384 nlp2024(kana,kanji)+…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "render_train_output(pathstr(\"./output/nlp2024/radical384 nlp2024(kana,kanji)+KVG(pad={4,8,12,16},sw=2)\"), [1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fa94f1-eb50-4b40-89cf-ab58ec42a2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion3.9",
   "language": "python",
   "name": "diffusion3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
